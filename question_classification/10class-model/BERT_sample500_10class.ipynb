{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch, torchdata, torchtext\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.2.2+cu121', '0.7.1', '0.17.2+cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__, torchdata.__version__, torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234 #change three times\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>questionText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toys_and_Games</td>\n",
       "      <td>Many have stated similar to the following: \"Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Health_and_Personal_Care</td>\n",
       "      <td>Will these work with the Phillips sonicare han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cell_Phones_and_Accessories</td>\n",
       "      <td>What kind of sim card it use?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen</td>\n",
       "      <td>does anyone know if this dinnerware set does n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Musical_Instruments</td>\n",
       "      <td>I'm thinking of getting in to modular synthesi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      category  \\\n",
       "0               Toys_and_Games   \n",
       "1     Health_and_Personal_Care   \n",
       "2  Cell_Phones_and_Accessories   \n",
       "3             Home_and_Kitchen   \n",
       "4          Musical_Instruments   \n",
       "\n",
       "                                        questionText  \n",
       "0  Many have stated similar to the following: \"Pa...  \n",
       "1  Will these work with the Phillips sonicare han...  \n",
       "2                      What kind of sim card it use?  \n",
       "3  does anyone know if this dinnerware set does n...  \n",
       "4  I'm thinking of getting in to modular synthesi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('../data/train-qar.jsonl', lines=True, nrows=300000)\n",
    "df = df[['category', 'questionText']]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Toys_and_Games', 'Health_and_Personal_Care',\n",
       "       'Cell_Phones_and_Accessories', 'Home_and_Kitchen',\n",
       "       'Musical_Instruments', 'Baby', 'Sports_and_Outdoors',\n",
       "       'Patio_Lawn_and_Garden', 'Video_Games', 'Pet_Supplies',\n",
       "       'Tools_and_Home_Improvement', 'Beauty', 'Electronics',\n",
       "       'Grocery_and_Gourmet_Food', 'Automotive', 'Office_Products',\n",
       "       'Clothing_Shoes_and_Jewelry'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Product category\n",
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Electronics                    69163\n",
       "Home_and_Kitchen               43733\n",
       "Sports_and_Outdoors            28873\n",
       "Tools_and_Home_Improvement     25503\n",
       "Health_and_Personal_Care       19230\n",
       "Automotive                     18688\n",
       "Cell_Phones_and_Accessories    17052\n",
       "Patio_Lawn_and_Garden          14845\n",
       "Toys_and_Games                 12599\n",
       "Office_Products                10436\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the text to numeric class\n",
    "# class_mapping = {\n",
    "#     'Toys_and_Games': 0,\n",
    "#     'Health_and_Personal_Care': 1,\n",
    "#     'Cell_Phones_and_Accessories': 2,\n",
    "#     'Home_and_Kitchen': 3,\n",
    "#     'Musical_Instruments': 4,\n",
    "#     'Baby': 5,\n",
    "#     'Sports_and_Outdoors': 6,\n",
    "#     'Patio_Lawn_and_Garden': 7,\n",
    "#     'Video_Games': 8,\n",
    "#     'Pet_Supplies': 9,\n",
    "#     'Tools_and_Home_Improvement': 10,\n",
    "#     'Beauty': 11,\n",
    "#     'Electronics': 12,\n",
    "#     'Grocery_and_Gourmet_Food': 13,\n",
    "#     'Automotive': 14,\n",
    "#     'Office_Products': 15,\n",
    "#     'Clothing_Shoes_and_Jewelry': 16\n",
    "# }\n",
    "\n",
    "class_mapping = {\n",
    "    'Electronics': 0,\n",
    "    'Home_and_Kitchen': 1,\n",
    "    'Sports_and_Outdoors': 2,\n",
    "    'Tools_and_Home_Improvement': 3,\n",
    "    'Health_and_Personal_Care': 4,\n",
    "    'Automotive': 5,\n",
    "    'Cell_Phones_and_Accessories': 6,\n",
    "    'Patio_Lawn_and_Garden': 7,\n",
    "    'Toys_and_Games': 8,\n",
    "    'Office_Products': 9\n",
    "}\n",
    "\n",
    "# Map class names to numerical labels\n",
    "df['category'] = df['category'].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 100 data in each classes\n",
    "df_sample = df.groupby('category', group_keys=False).apply(lambda x: x.sample(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lower case\n",
    "df_sample['questionText']  =  df_sample['questionText'].apply(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(data):\n",
    "    regex_s = re.sub(\"\\\\(.+?\\\\)|[\\r\\n|\\n\\r]|!\", \"\", data)\n",
    "    fin = \" \".join(regex_s.split())\n",
    "    return fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['questionText'] = df_sample['questionText'].apply(data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.astype({'category':int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df_sample, test_size=0.1,stratify=df_sample['category'], random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(train_df, test_size=0.1, stratify=train_df['category'],random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "4    405\n",
       "3    405\n",
       "7    405\n",
       "0    405\n",
       "9    405\n",
       "1    405\n",
       "6    405\n",
       "5    405\n",
       "8    405\n",
       "2    405\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>questionText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165169</th>\n",
       "      <td>4</td>\n",
       "      <td>does it allow you to program in weight and hei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39913</th>\n",
       "      <td>3</td>\n",
       "      <td>what's difference dds180-2 and dds181-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>7</td>\n",
       "      <td>wondering if anyone else has had problems with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14466</th>\n",
       "      <td>0</td>\n",
       "      <td>will it fit on a keyring comfortably?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64656</th>\n",
       "      <td>9</td>\n",
       "      <td>will this work with an office star 5500 space ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256459</th>\n",
       "      <td>8</td>\n",
       "      <td>does this case fit the crazy loom from toys r ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259612</th>\n",
       "      <td>4</td>\n",
       "      <td>this says \"with removable back rest\" but how d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291157</th>\n",
       "      <td>1</td>\n",
       "      <td>are the shelf pins metal or plastic? and what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9347</th>\n",
       "      <td>7</td>\n",
       "      <td>how many blocks in this bucket?will this kill ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108599</th>\n",
       "      <td>2</td>\n",
       "      <td>do you know what the height is from the floor ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4050 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                       questionText\n",
       "165169         4  does it allow you to program in weight and hei...\n",
       "39913          3            what's difference dds180-2 and dds181-2\n",
       "1903           7  wondering if anyone else has had problems with...\n",
       "14466          0              will it fit on a keyring comfortably?\n",
       "64656          9  will this work with an office star 5500 space ...\n",
       "...          ...                                                ...\n",
       "256459         8  does this case fit the crazy loom from toys r ...\n",
       "259612         4  this says \"with removable back rest\" but how d...\n",
       "291157         1  are the shelf pins metal or plastic? and what ...\n",
       "9347           7  how many blocks in this bucket?will this kill ...\n",
       "108599         2  do you know what the height is from the floor ...\n",
       "\n",
       "[4050 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = 'bert-base-uncased'\n",
    "max_length = 128\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "train_dataset = TextClassificationDataset(train_df['questionText'].tolist(), train_df['category'].tolist(), tokenizer, max_length)\n",
    "val_dataset = TextClassificationDataset(val_df['questionText'].tolist(), val_df['category'].tolist(), tokenizer, max_length)\n",
    "test_dataset = TextClassificationDataset(test_df['questionText'].tolist(), test_df['category'].tolist(), tokenizer, max_length)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model (BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_classes):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc1 = nn.Linear(768, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        x = self.dropout(pooled_output)\n",
    "        x = self.fc1(x)\n",
    "        logits = self.fc2(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        \n",
    "        correct_predictions += torch.sum(preds == labels).item()\n",
    "        total_predictions += len(labels)\n",
    "        \n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    epoch_loss /= len(data_loader)  # Average loss per batch\n",
    "    return epoch_loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels).item()\n",
    "            total_predictions += len(labels)\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    epoch_loss /= len(data_loader)  # Average loss per batch\n",
    "    return  epoch_loss,accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/pydantic/_internal/_config.py:334: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/252120056759092590', creation_time=1714100306850, experiment_id='252120056759092590', last_update_time=1714100306850, lifecycle_stage='active', name='BERT500', tags={}>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment tracking\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "import os\n",
    "\n",
    "# This the dockerized method.\n",
    "# We build two docker containers, one for python/jupyter and another for mlflow.\n",
    "# The url `mlflow` is resolved into another container within the same composer.\n",
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "# In the dockerized way, the user who runs this code will be `root`.\n",
    "# The MLflow will also log the run user_id as `root`.\n",
    "# To change that, we need to set this environ[\"LOGNAME\"] to your name.\n",
    "os.environ[\"LOGNAME\"] = \"noppawee\"\n",
    "#mlflow.create_experiment(name=\"noppawee-ML-project\")  #create if you haven't create\n",
    "mlflow.set_experiment(experiment_name=\"BERT500\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = 'bert-base-uncased'\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = BERTClassifier(bert_model_name, num_classes).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Time: 4m 55s\n",
      "\tTrain Loss: 2.354 | Train Acc: 11.70%\n",
      "\tVal.  Loss: 2.270 | Val Acc: 14.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Time: 4m 57s\n",
      "\tTrain Loss: 2.305 | Train Acc: 13.95%\n",
      "\tVal.  Loss: 2.238 | Val Acc: 18.60%\n",
      "Epoch: 3 | Time: 4m 53s\n",
      "\tTrain Loss: 2.256 | Train Acc: 15.65%\n",
      "\tVal.  Loss: 2.267 | Val Acc: 13.00%\n",
      "Epoch: 4 | Time: 5m 3s\n",
      "\tTrain Loss: 2.224 | Train Acc: 18.52%\n",
      "\tVal.  Loss: 2.241 | Val Acc: 17.00%\n",
      "Epoch: 5 | Time: 5m 1s\n",
      "\tTrain Loss: 2.200 | Train Acc: 19.88%\n",
      "\tVal.  Loss: 2.181 | Val Acc: 21.80%\n",
      "Epoch: 6 | Time: 4m 55s\n",
      "\tTrain Loss: 2.190 | Train Acc: 21.28%\n",
      "\tVal.  Loss: 2.130 | Val Acc: 24.40%\n",
      "Epoch: 7 | Time: 4m 56s\n",
      "\tTrain Loss: 2.170 | Train Acc: 21.09%\n",
      "\tVal.  Loss: 2.112 | Val Acc: 24.20%\n",
      "Epoch: 8 | Time: 4m 55s\n",
      "\tTrain Loss: 2.154 | Train Acc: 22.81%\n",
      "\tVal.  Loss: 2.119 | Val Acc: 24.40%\n",
      "Epoch: 9 | Time: 4m 53s\n",
      "\tTrain Loss: 2.145 | Train Acc: 23.11%\n",
      "\tVal.  Loss: 2.112 | Val Acc: 22.80%\n",
      "Epoch: 10 | Time: 4m 58s\n",
      "\tTrain Loss: 2.121 | Train Acc: 24.25%\n",
      "\tVal.  Loss: 2.091 | Val Acc: 25.20%\n",
      "Epoch: 11 | Time: 4m 53s\n",
      "\tTrain Loss: 2.113 | Train Acc: 24.94%\n",
      "\tVal.  Loss: 2.084 | Val Acc: 26.80%\n",
      "Epoch: 12 | Time: 4m 55s\n",
      "\tTrain Loss: 2.100 | Train Acc: 24.74%\n",
      "\tVal.  Loss: 2.062 | Val Acc: 25.60%\n",
      "Epoch: 13 | Time: 5m 0s\n",
      "\tTrain Loss: 2.093 | Train Acc: 26.72%\n",
      "\tVal.  Loss: 2.077 | Val Acc: 24.80%\n",
      "Epoch: 14 | Time: 4m 56s\n",
      "\tTrain Loss: 2.086 | Train Acc: 25.73%\n",
      "\tVal.  Loss: 2.083 | Val Acc: 28.80%\n",
      "Epoch: 15 | Time: 5m 2s\n",
      "\tTrain Loss: 2.076 | Train Acc: 27.06%\n",
      "\tVal.  Loss: 2.073 | Val Acc: 26.80%\n",
      "Epoch: 16 | Time: 4m 57s\n",
      "\tTrain Loss: 2.065 | Train Acc: 27.88%\n",
      "\tVal.  Loss: 2.064 | Val Acc: 26.60%\n",
      "Epoch: 17 | Time: 5m 3s\n",
      "\tTrain Loss: 2.067 | Train Acc: 27.95%\n",
      "\tVal.  Loss: 2.051 | Val Acc: 28.20%\n",
      "Epoch: 18 | Time: 4m 57s\n",
      "\tTrain Loss: 2.056 | Train Acc: 29.09%\n",
      "\tVal.  Loss: 2.042 | Val Acc: 29.00%\n",
      "Epoch: 19 | Time: 4m 57s\n",
      "\tTrain Loss: 2.052 | Train Acc: 28.44%\n",
      "\tVal.  Loss: 2.046 | Val Acc: 29.80%\n",
      "Epoch: 20 | Time: 5m 3s\n",
      "\tTrain Loss: 2.051 | Train Acc: 30.20%\n",
      "\tVal.  Loss: 2.042 | Val Acc: 29.40%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "params={\"model\":\"BERT\", \"num_epochs\":num_epochs,\"lr\":learning_rate}\n",
    "mlflow.start_run(run_name=f\"BERT500-{params['num_epochs']}-epochs-lr-{params['lr']}-10-classes-2layers\")\n",
    "mlflow.log_params(params)\n",
    "\n",
    "\n",
    "\n",
    "train_losses, train_accs, val_losses, val_accs = [],[],[],[]\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "                \n",
    "    train_loss, train_acc = train(model, train_dataloader, optimizer, scheduler, device)\n",
    "    valid_loss, valid_acc = evaluate(model, val_dataloader, device)\n",
    "    #for plotting\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(valid_loss)\n",
    "    val_accs.append(valid_acc)\n",
    "                \n",
    "    end_time = time.time()\n",
    "                \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    mlflow.log_metric(key=\"train_loss\", value=train_loss, step=epoch)\n",
    "    mlflow.log_metric(key=\"train_acc\", value=train_acc, step=epoch)\n",
    "    mlflow.log_metric(key=\"val_loss\", value=valid_loss, step=epoch)\n",
    "    mlflow.log_metric(key=\"val_acc\", value=valid_acc, step=epoch)\n",
    "                \n",
    "            \n",
    "    #early stopping\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        mlflow.pytorch.log_model(model, \"model\")\n",
    "                \n",
    "    print(f'Epoch: {epoch+1} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\tVal.  Loss: {valid_loss:.3f} | Val Acc: {valid_acc*100:.2f}%')\n",
    "mlflow.log_metric(key=\"min_val_loss\", value=min(val_losses), step=epoch)    \n",
    "mlflow.end_run()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_sentiment(text, model, tokenizer, device, max_length=128):\n",
    "#     model.eval()\n",
    "#     encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
    "#     input_ids = encoding['input_ids'].to(device)\n",
    "#     attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         _, preds = torch.max(outputs, dim=1)\n",
    "#     return \"positive\" if preds.item() == 1 else \"negative\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
