{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minnb\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.agents import Tool\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading sample json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "csv_file_path = 'data/product-data/product_data.csv'\n",
    "\n",
    "# Initialize the CSVLoader with a specified encoding (e.g., 'utf-8')\n",
    "loader = CSVLoader(csv_file_path, encoding='utf-8')\n",
    "\n",
    "# Load the documents\n",
    "try:\n",
    "    documents = loader.load()\n",
    "    print(\"Documents loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading documents: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Uniq Id: 66d49bbed043f5be260fa9f7fbff5957\\nProduct Name: Electronic Snap Circuits Mini Kits Classpack, FM Radio, Motion Detector, Music Box (Set of 5)\\nBrand Name: \\nAsin: \\nCategory: Toys & Games | Learning & Education | Science Kits & Toys\\nUpc Ean Code: \\nList Price: \\nSelling Price: $99.95\\nQuantity: \\nModel Number: 55324\\nAbout Product: Make sure this fits by entering your model number. | Snap circuits mini kits classpack provides basic electronic circuitry activities for students in grades 2-6 | Includes 5 separate mini building kits- an FM radio, a motion detector, music box, space battle sound effects, and a flying saucer | Each kit includes separate components and instructions to build | Each component represents one function in a circuit; components snap together to create working models of everyday electronic devices | Activity guide provides additional projects to teach students how circuitry works\\nProduct Specification: Product Dimensions:         14.7 x 11.1 x 10.2 inches ; 4.06 pounds    |Shipping Weight: 4 pounds (View shipping rates and policies)|Domestic Shipping: Item can be shipped within U.S.|International Shipping: This item can be shipped to select countries outside of the U.S.  Learn More|ASIN: B008AK6DAS|Item model number: 55324|    #3032    in\\xa0Science Kits & Toys\\nTechnical Details: The snap circuits mini kits classpack provides basic electric circuitry information for students in grades 2-6. This classpack includes 5 snap-together building kits. Components snap together to create working models of everyday electronic devices. Kits included are an FM radio, a motion detector, a music box, space battle sound effects, and a flying saucer. Each mini kit comes with individual components, and an activity guide which includes instructions and additional project ideas. Each primary-colored component represents one function in a circuit. Activity kits are used by teachers and students in classroom and homeschool settings for educational and research applications in science, math, and for a variety of additional disciplines. Science education products and manipulatives incorporate applied math and science principles into classroom or homeschool projects. Teachers in pre-K, elementary, and secondary classrooms use science education kits, manipualtives, and products alongside science, technology, engineering, and math (STEM) curriculum to demonstrate STEM concepts and real-world applications through hands-on activities. Science education projects include a broad range of activities, such as practical experiments in engineering, aeronautics, robotics, chemistry, physics, biology, and geology.\\nShipping Weight: 4 pounds\\nProduct Dimensions: 14.7 x 11.1 x 10.2 inches  4.06 pounds\\nImage: https://images-na.ssl-images-amazon.com/images/I/51M0KnJxjKL.jpg|https://images-na.ssl-images-amazon.com/images/I/5166GD8OkXL.jpg|https://images-na.ssl-images-amazon.com/images/I/61o5S1VnaNL.jpg|https://images-na.ssl-images-amazon.com/images/I/61t4Q0rPYjL.jpg|https://images-na.ssl-images-amazon.com/images/I/61NASUAyqcL.jpg|https://images-na.ssl-images-amazon.com/images/I/51OMrADdyJL.jpg|https://images-na.ssl-images-amazon.com/images/G/01/x-locale/common/transparent-pixel.jpg\\nVariants: \\nSku: \\nProduct Url: https://www.amazon.com/Electronic-Circuits-Classpack-Motion-Detector/dp/B008AK6DAS\\nStock: \\nProduct Details: \\nDimensions: \\nColor: \\nIngredients: \\nDirection To Use: \\nIs Amazon Seller: Y\\nSize Quantity Variant: \\nProduct Description: ', metadata={'source': 'data/product-data/product_data.csv', 'row': 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 700,\n",
    "    chunk_overlap = 100\n",
    ")\n",
    "\n",
    "doc = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='About Product: Make sure this fits by entering your model number. | RESPONSIVE FLEX: The Crossbow features a bamboo core encased in triaxial fiberglass and HD plastic for a responsive flex pattern that’s second to none. Pumping & carving have never been so satisfying! Flex 2 is recommended for people 120 to 170 pounds. | COREFLEX TECH: CoreFlex construction is water resistant, impact resistant, scratch resistant and has a flex like you won’t believe. These boards combine fiberglass, epoxy, HD plastic and bamboo to create a perfect blend of performance and strength. | INSPIRED BY THE NORTHWEST: Our founding ideal is chasing adventure & riding the best boards possible, inspired by the hills,', metadata={'source': 'data/product-data/product_data.csv', 'row': 0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50885"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lim = doc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings and vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "model_name = 'hkunlp/instructor-base'\n",
    "\n",
    "embedding_model = HuggingFaceInstructEmbeddings(\n",
    "    model_name = model_name,\n",
    "    model_kwargs = {\"device\" : device}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate vectorstore\n",
    "vector_path = './vector-store'\n",
    "if not os.path.exists(vector_path):\n",
    "    os.makedirs(vector_path)\n",
    "    print('create path done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save vector locally\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.from_documents(\n",
    "    documents = doc_lim,\n",
    "    embedding = embedding_model\n",
    ")\n",
    "\n",
    "db_file_name = 'nlp-project-product-data'\n",
    "\n",
    "vectordb.save_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    index_name = 'nlp' #default index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling vector from local\n",
    "vector_path = './vector-store'\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.load_local(\n",
    "    folder_path = os.path.join(vector_path, db_file_name),\n",
    "    embeddings = embedding_model,\n",
    "    index_name = 'nlp' #default index\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ready to use\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Uniq Id: ed8d9032bc6d9f45b4db9209d693fdc0\\nProduct Name: Martha Stewart Crafts Stencil Tape, 32292\\nBrand Name: \\nAsin: \\nCategory: Arts, Crafts & Sewing | Crafting | Paper & Paper Crafts | Paper Craft Tools\\nUpc Ean Code: \\nList Price: \\nSelling Price: $9.97\\nQuantity: \\nModel Number: 32292\\nAbout Product: Create plaids, stripes and checkerboards | Low tack adhesive | Easily removed | Holds stencils securely in place | Prevents run under of paint', metadata={'source': 'data/product-data/product_data.csv', 'row': 101}),\n",
       " Document(page_content='moisture absorption, and is non-conductive. The ball is latex free for latex sensitivity. Science education products are commonly used as educational aids in scientific classrooms and office settings. Science education products incorporate applied math and science principles into classroom and homeschool-based projects. Teachers in pre-K, elementary, and secondary classrooms use science education kits and products alongside science, technology, engineering, and math (STEM) curriculum to demonstrate STEM concepts and real-world applications through hands-on activities. Science education projects include a broad range of activities, such as practical experiments in engineering, aeronautics,', metadata={'source': 'data/product-data/product_data.csv', 'row': 116}),\n",
       " Document(page_content='Uniq Id: 1ecccb43e0f5c0162218371916ffa553\\nProduct Name: C&D Visionary DC Comic Originals Flash Logo Sticker\\nBrand Name: \\nAsin: \\nCategory: Toys & Games | Arts & Crafts | Craft Kits\\nUpc Ean Code: \\nList Price: \\nSelling Price: $4.99\\nQuantity: \\nModel Number: S-DC-0140\\nAbout Product: Make sure this fits by entering your model number. | Sticker is great for Walls, Doors, Desks, Guitars, Cars, Windows, and Notebooks | Comes ready to install, just peel the back and apply on clean surface | Great to be used on any scrapbooking projects | The absolute best sticker you will ever own is now available', metadata={'source': 'data/product-data/product_data.csv', 'row': 14}),\n",
       " Document(page_content='Product Specification: ProductDimensions:8.8x0.8x4.5inches|ShippingWeight:2.4ounces(Viewshippingratesandpolicies)|DomesticShipping:ItemcanbeshippedwithinU.S.|InternationalShipping:ThisitemcanbeshippedtoselectcountriesoutsideoftheU.S.LearnMore|Itemmodelnumber:32292|ASIN:B007C7XUI8\\nTechnical Details: 2.4 ounces (View shipping rates and policies) | show up to 2 reviews by default Martha Stewart stencil tape. Low-tack tape is safe for fabrics and other surfaces. Use to hold stencils securely in place or to mask off areas while stenciling. Contains one roll, 3/4-inch-by-25-yards. Made in the USA\\nShipping Weight: 2.4 ounces\\nProduct Dimensions:', metadata={'source': 'data/product-data/product_data.csv', 'row': 101})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"What is Glue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate models\n",
    "model_path = './models'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    print('create path done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ./models\n",
    "# !git clone https://huggingface.co/anas-awadalla/gpt2-span-head-few-shot-k-16-finetuned-squad-seed-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, pipeline, AutoModelForCausalLM\n",
    "from transformers import BitsAndBytesConfig\n",
    "from langchain import HuggingFacePipeline\n",
    "import torch\n",
    "\n",
    "model_id = 'models/gpt2-span-head-few-shot-k-16-finetuned-squad-seed-0/'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "bitsandbyte_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bitsandbyte_config,\n",
    "    device_map='cuda:0',\n",
    "    load_in_8bit=True\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=100,\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0,\n",
    "        \"repetition_penalty\": 1.5\n",
    "    }\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONDENSE_QUESTION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generator = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = CONDENSE_QUESTION_PROMPT,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minnb\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "Human:What is Machine Learning\n",
      "AI:\n",
      "Human:What is Deep Learning\n",
      "AI:\n",
      "Follow Up Input: Comparing both of them\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': 'Human:What is Machine Learning\\nAI:\\nHuman:What is Deep Learning\\nAI:',\n",
       " 'question': 'Comparing both of them',\n",
       " 'text': ' \"What is Machine Learning?\"\\n\"What type of Machine Learning is that?\"This may seem counterintuitive. It may sound counterintuitive at first. Machine learning seems to be able to \"learn\" anything, anywhere. It can remember what you searched for the next time you looked, when you gave it a try, and then from that you could make a judgment about the product. It was able to figure out which states of affairs to buy, which currencies to buy, which parts to sell,'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Comparing both of them'\n",
    "chat_history = \"Human:What is Machine Learning\\nAI:\\nHuman:What is Deep Learning\\nAI:\"\n",
    "\n",
    "question_generator({'chat_history' : chat_history, \"question\" : query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template='Test prompt for NLP Amazon sales chatbot.\\n    {context}\\n    Question: {question}\\n    Answer:')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "    Test prompt for NLP Amazon sales chatbot.\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    Answer:\n",
    "    \"\"\".strip()\n",
    "\n",
    "PROMPT = PromptTemplate.from_template(\n",
    "    template = prompt_template\n",
    ")\n",
    "\n",
    "PROMPT\n",
    "#using str.format \n",
    "#The placeholder is defined using curly brackets: {} {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], template='Test prompt for NLP Amazon sales chatbot.\\n    {context}\\n    Question: {question}\\n    Answer:'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x000001C7F6C86F10>)), document_variable_name='context')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_chain = load_qa_chain(\n",
    "    llm = llm,\n",
    "    chain_type = 'stuff',\n",
    "    prompt = PROMPT,\n",
    "    verbose = True\n",
    ")\n",
    "doc_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationalRetrievalChain(memory=ConversationBufferWindowMemory(output_key='answer', return_messages=True, memory_key='chat_history', k=3), verbose=True, combine_docs_chain=StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['context', 'question'], template='Test prompt for NLP Amazon sales chatbot.\\n    {context}\\n    Question: {question}\\n    Answer:'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x000001C7F6C86F10>)), document_variable_name='context'), question_generator=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x000001C7F6C86F10>)), return_source_documents=True, get_chat_history=<function <lambda> at 0x000001C88B6A6DE0>, retriever=VectorStoreRetriever(tags=['FAISS', 'HuggingFaceInstructEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001C7C434A250>))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferWindowMemory(\n",
    "    k=3, \n",
    "    memory_key = \"chat_history\",\n",
    "    return_messages = True,\n",
    "    output_key = 'answer'\n",
    ")\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=retriever,\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents=True,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    get_chat_history=lambda h : h\n",
    ")\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mTest prompt for NLP Amazon sales chatbot.\n",
      "    About Product: Make sure this fits by entering your model number. | RESPONSIVE FLEX: The Crossbow features a bamboo core encased in triaxial fiberglass and HD plastic for a responsive flex pattern that’s second to none. Pumping & carving have never been so satisfying! Flex 2 is recommended for people 120 to 170 pounds. | COREFLEX TECH: CoreFlex construction is water resistant, impact resistant, scratch resistant and has a flex like you won’t believe. These boards combine fiberglass, epoxy, HD plastic and bamboo to create a perfect blend of performance and strength. | INSPIRED BY THE NORTHWEST: Our founding ideal is chasing adventure & riding the best boards possible, inspired by the hills,\n",
      "\n",
      "Uniq Id: 4c69b61db1fc16e7013b43fc926e502d\n",
      "Product Name: DB Longboards CoreFlex Crossbow 41\" Bamboo Fiberglass Longboard Complete\n",
      "Brand Name: \n",
      "Asin: \n",
      "Category: Sports & Outdoors | Outdoor Recreation | Skates, Skateboards & Scooters | Skateboarding | Standard Skateboards & Longboards | Longboards\n",
      "Upc Ean Code: \n",
      "List Price: \n",
      "Selling Price: $237.68\n",
      "Quantity: \n",
      "Model Number:\n",
      "\n",
      "Variants: \n",
      "Sku: \n",
      "Product Url: https://www.amazon.com/Blade-BLH-H-130-Basic-Safe/dp/B06XN5BCK1\n",
      "Stock: \n",
      "Product Details: \n",
      "Dimensions: \n",
      "Color: \n",
      "Ingredients: \n",
      "Direction To Use: \n",
      "Is Amazon Seller: Y\n",
      "Size Quantity Variant: \n",
      "Product Description:\n",
      "\n",
      "Variants:\n",
      "    Question: Can you tell me what crossbows are available?\n",
      "    Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you tell me what crossbows are available?',\n",
       " 'chat_history': [],\n",
       " 'answer': ' \\n    Based on  _________\\nIn other words,  _________\\nX Previous image Next image Previous 3 remaining Images with http://stock.treasurer.com/item/4242X-ARB-STRONGBOOTS/ A search for \"4241X-ARB-STRONGBOOTS\" turned up no less than 36 box sets of the legendary Barbarian armor set! Now a whole lot of people are having fun plinking their way into our local',\n",
       " 'source_documents': [Document(page_content='About Product: Make sure this fits by entering your model number. | RESPONSIVE FLEX: The Crossbow features a bamboo core encased in triaxial fiberglass and HD plastic for a responsive flex pattern that’s second to none. Pumping & carving have never been so satisfying! Flex 2 is recommended for people 120 to 170 pounds. | COREFLEX TECH: CoreFlex construction is water resistant, impact resistant, scratch resistant and has a flex like you won’t believe. These boards combine fiberglass, epoxy, HD plastic and bamboo to create a perfect blend of performance and strength. | INSPIRED BY THE NORTHWEST: Our founding ideal is chasing adventure & riding the best boards possible, inspired by the hills,', metadata={'source': 'data/product-data/product_data.csv', 'row': 0}),\n",
       "  Document(page_content='Uniq Id: 4c69b61db1fc16e7013b43fc926e502d\\nProduct Name: DB Longboards CoreFlex Crossbow 41\" Bamboo Fiberglass Longboard Complete\\nBrand Name: \\nAsin: \\nCategory: Sports & Outdoors | Outdoor Recreation | Skates, Skateboards & Scooters | Skateboarding | Standard Skateboards & Longboards | Longboards\\nUpc Ean Code: \\nList Price: \\nSelling Price: $237.68\\nQuantity: \\nModel Number:', metadata={'source': 'data/product-data/product_data.csv', 'row': 0}),\n",
       "  Document(page_content='Variants: \\nSku: \\nProduct Url: https://www.amazon.com/Blade-BLH-H-130-Basic-Safe/dp/B06XN5BCK1\\nStock: \\nProduct Details: \\nDimensions: \\nColor: \\nIngredients: \\nDirection To Use: \\nIs Amazon Seller: Y\\nSize Quantity Variant: \\nProduct Description:', metadata={'source': 'data/product-data/product_data.csv', 'row': 86}),\n",
       "  Document(page_content='Variants:', metadata={'source': 'data/product-data/product_data.csv', 'row': 25})]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_question = \"Can you tell me what crossbows are available?\"\n",
    "answer = chain({\"question\":prompt_question})\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
