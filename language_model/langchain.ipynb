{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.agents import Tool\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import dill\n",
    "import re\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForSeq2SeqLM, AutoModelForCausalLM, AutoModelForQuestionAnswering\n",
    "from transformers import BitsAndBytesConfig\n",
    "from langchain import HuggingFacePipeline\n",
    "import torch\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings and vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "model_name = 'hkunlp/instructor-base'\n",
    "\n",
    "embedding_model = HuggingFaceInstructEmbeddings(\n",
    "    model_name = model_name,\n",
    "    model_kwargs = {\"device\" : device}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate vectorstore\n",
    "vector_path = './vector_stores'\n",
    "if not os.path.exists(vector_path):\n",
    "    os.makedirs(vector_path)\n",
    "    print('create path done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text_str):\n",
    "    text_str = text_str.lower()\n",
    "    device = 'cpu'\n",
    "    regex_s = re.sub(\"\\\\(.+?\\\\)|[\\r\\n|\\n\\r]|!\", \"\", text_str)\n",
    "    text = \" \".join(regex_s.split())\n",
    "    tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "    loaded_model = torch.jit.load('../question_classification/CNN.pt')\n",
    "    with open('../question_classification/vocab.pkl', 'rb') as f:\n",
    "        loaded_vocab = dill.load(f)\n",
    "    text = torch.tensor(loaded_vocab(tokenizer(text))).to(device)\n",
    "    text = text.reshape(1, -1)\n",
    "    with torch.no_grad():\n",
    "        output = loaded_model(text).squeeze(1)\n",
    "        predicted = torch.max(output.data, 1)[1]\n",
    "        return predicted.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"What rice cookers are available?\"\n",
    "predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'Toys_and_Games', 'Health_and_Personal_Care', 'Cell_Phones_and_Accessories', \n",
    "    'Home_and_Kitchen', 'Musical_Instruments', 'Baby_Products', 'Sports_and_Outdoors', \n",
    "    'Patio_Lawn_and_Garden', 'Video_Games', 'Pet_Supplies', 'Tools_and_Home_Improvement', \n",
    "    'Beauty_and_Personal_Care', 'Electronics', 'Automotive', 'Office_Products', \n",
    "    'Amazon_Fashion'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Automotive'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Automotive'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories[predict(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_vector_store(text, size):\n",
    "\n",
    "    category = categories[predict(text)]\n",
    "    #calling vector from local\n",
    "    vector_path = './vector_stores'\n",
    "\n",
    "    from langchain.vectorstores import FAISS\n",
    "\n",
    "    db_file_name = f\"{size}/{category}\"\n",
    "\n",
    "    vectordb = FAISS.load_local(\n",
    "        folder_path = os.path.join(vector_path, db_file_name),\n",
    "        embeddings = embedding_model,\n",
    "        index_name = f'{category}' #default index\n",
    "    )\n",
    "    retriever = vectordb.as_retriever()\n",
    "\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locate models\n",
    "model_path = './models'\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "    print('create path done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd ./models\n",
    "# !git clone https://huggingface.co/anas-awadalla/gpt2-span-head-few-shot-k-16-finetuned-squad-seed-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt2_model(temp = 0, rep = 1.5):\n",
    "    model_id = 'models/gpt2-span-head-few-shot-k-16-finetuned-squad-seed-0/'\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_id)\n",
    "\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    bitsandbyte_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        quantization_config=bitsandbyte_config,\n",
    "        device_map='cuda:0',\n",
    "        load_in_8bit=True\n",
    "    )\n",
    "\n",
    "    pipe = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        task=\"text-generation\",\n",
    "        max_new_tokens=100,\n",
    "        model_kwargs={\n",
    "            \"temperature\": temp,\n",
    "            \"repetition_penalty\": rep\n",
    "        }\n",
    "    )\n",
    "\n",
    "    llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t5_model(temp = 0, rep = 1.5):\n",
    "    model_id = './models/fastchat-t5-3b-v1.0/'\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_id)\n",
    "\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    bitsandbyte_config = BitsAndBytesConfig(\n",
    "        load_in_4bit = True,\n",
    "        bnb_4bit_quant_type = \"nf4\",\n",
    "        bnb_4bit_compute_dtype = torch.float16,\n",
    "        bnb_4bit_use_double_quant = True\n",
    "    )\n",
    "\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        model_id,\n",
    "        quantization_config = bitsandbyte_config, #caution Nvidia\n",
    "        device_map = 'auto',\n",
    "        load_in_8bit = True\n",
    "    )\n",
    "\n",
    "    pipe = pipeline(\n",
    "        task=\"text2text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens = 100,\n",
    "        model_kwargs = {\n",
    "            \"temperature\" : temp,\n",
    "            \"repetition_penalty\": rep\n",
    "        }\n",
    "    )\n",
    "\n",
    "    llm = HuggingFacePipeline(pipeline = pipe)\n",
    "\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tinyroberta_model():\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    pipe = pipeline('question-answering', model=model, tokenizer=tokenizer)\n",
    "\n",
    "    llm = HuggingFacePipeline(pipeline = pipe)\n",
    "\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['chat_history', 'question'], template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONDENSE_QUESTION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chain(llm, retriever):\n",
    "    question_generator = LLMChain(\n",
    "        llm = llm,\n",
    "        prompt = CONDENSE_QUESTION_PROMPT,\n",
    "        verbose = True\n",
    "    )\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "        Test prompt for NLP Amazon sales chatbot.\n",
    "        {context}\n",
    "        Question: {question}\n",
    "        Answer:\n",
    "        \"\"\".strip()\n",
    "\n",
    "    PROMPT = PromptTemplate.from_template(\n",
    "        template = prompt_template\n",
    "    )\n",
    "\n",
    "    PROMPT\n",
    "    #using str.format \n",
    "    #The placeholder is defined using curly brackets: {} {}\n",
    "    doc_chain = load_qa_chain(\n",
    "        llm = llm,\n",
    "        chain_type = 'stuff',\n",
    "        prompt = PROMPT,\n",
    "        verbose = True\n",
    "    )\n",
    "\n",
    "    memory = ConversationBufferWindowMemory(\n",
    "        k=1, \n",
    "        memory_key = \"chat_history\",\n",
    "        return_messages = True,\n",
    "        output_key = 'answer'\n",
    "    )\n",
    "\n",
    "    chain = ConversationalRetrievalChain(\n",
    "        retriever=retriever,\n",
    "        question_generator=question_generator,\n",
    "        combine_docs_chain=doc_chain,\n",
    "        return_source_documents=True,\n",
    "        memory=memory,\n",
    "        verbose=True,\n",
    "        get_chat_history=lambda h : h\n",
    "    )\n",
    "    \n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_answer(prompt_question, llm):\n",
    "    torch.cuda.empty_cache()\n",
    "    retriever = choose_vector_store(prompt_question, 100)\n",
    "    chain = create_chain(llm, retriever)\n",
    "    answer = chain({\"question\":prompt_question})\n",
    "\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mTest prompt for NLP Amazon sales chatbot.\n",
      "        U.S. (Source: the npd Group). all knives feature high-carbon stainless steel blades which ensure the blades retain their ultra-sharp edge longer than conventional stainless steel. Each knife features an ergonomic metallic steel handle for greater durability. Set includes: 8-inch chef, 8-inch bread, 5-1/2-inch utility, 3-1/2-inch parer, 6 4.5-Inch steaks knives, all-purpose shears, sharpening shear and storage block with angled Heel. Not dishwasher safe. Hand wash with warm water and a mild detergent; rinse and dry immediately.\"], \"price\": \"None\", \"images\": {\"hi_res\": [\"https://m.media-amazon.com/images/I/81+3G1q1cgL._AC_SL1500_.jpg\",\n",
      "\n",
      "\"Kitchen Utensils & Gadgets\", \"Kitchen Knives & Accessories\", \"Knife Block Sets\"], \"details\": \"{\\\"Color\\\": \\\"Red\\\", \\\"Brand\\\": \\\"Farberware\\\", \\\"Blade Material\\\": \\\"Steel\\\", \\\"Blade Edge\\\": \\\"Serrated\\\", \\\"Item Dimensions LxWxH\\\": \\\"6.73 x 4.92 x 14.37 inches\\\", \\\"Style\\\": \\\"Ergonomic\\\", \\\"Number of Pieces\\\": \\\"13\\\", \\\"Is Dishwasher Safe\\\": \\\"No\\\", \\\"Handle Material\\\": \\\"Stainless Steel\\\", \\\"Construction Type\\\": \\\"Stamped\\\", \\\"Product Dimensions\\\": \\\"6.73 x 4.92 x 14.37 inches\\\", \\\"Item Weight\\\": \\\"6.24 pounds\\\", \\\"Manufacturer\\\": \\\"Farberware\\\", \\\"Item model number\\\": \\\"5191610\\\", \\\"Is Discontinued By Manufacturer\\\": \\\"No\\\", \\\"Date First Available\\\": \\\"November 8, 2017\\\"}\", \"parent_asin\":\n",
      "\n",
      "\"Kitchen Utensils & Gadgets\", \"Kitchen Knives & Accessories\", \"Asian Knives\", \"Sashimi Knives\"], \"details\": \"{\\\"Manufacturer\\\": \\\"Sekizo\\\", \\\"Item model number\\\": \\\"8115-A2L\\\", \\\"Is Discontinued By Manufacturer\\\": \\\"No\\\", \\\"Date First Available\\\": \\\"May 18, 2016\\\", \\\"Brand\\\": \\\"M.V. Trading\\\", \\\"Color\\\": \\\"Stainless Steel\\\", \\\"Handle Material\\\": \\\"Plastic,Steel\\\", \\\"Blade Edge\\\": \\\"Plain\\\", \\\"Blade Color\\\": \\\"Silver\\\"}\", \"parent_asin\": \"B01FV86UUY\", \"bought_together\": null, \"subtitle\": null, \"author\": null}\n",
      "\n",
      "\"/shop/wolfzoidgaming\", \"\", \"\", \"\", \"\", \"/shop/wolfzoidgaming\", \"\"]}, \"store\": \"VanlonPro\", \"categories\": [\"Home & Kitchen\", \"Kitchen & Dining\", \"Kitchen Utensils & Gadgets\", \"Kitchen Knives & Accessories\", \"Magnetic Knife Strips\"], \"details\": \"{\\\"Color\\\": \\\"Acrylic Shield\\\", \\\"Material\\\": \\\"Acrylic\\\", \\\"Brand\\\": \\\"VanlonPro\\\", \\\"Item Dimensions LxWxH\\\": \\\"8.66 x 1.57 x 9.45 inches\\\", \\\"Is Dishwasher Safe\\\": \\\"No\\\", \\\"Style\\\": \\\"Modern\\\", \\\"Product Dimensions\\\": \\\"8.66 x 1.57 x 9.45 inches\\\", \\\"Item Weight\\\": \\\"3.58 pounds\\\", \\\"Item model number\\\": \\\"Vanlon1199\\\", \\\"Best Sellers Rank\\\": {\\\"Kitchen & Dining\\\": 395687, \\\"Magnetic Knife Strips\\\": 253}, \\\"Date First Available\\\": \\\"October 17,\n",
      "        Question: Can you tell me what crossbows are available?\n",
      "        Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you tell me what crossbows are available?',\n",
       " 'chat_history': [],\n",
       " 'answer': ' Yes, 3 crossbows available at https://www.reddit.com/r/bowderbydesigns/\\n\\nThank you!\\n\\n1410 443 11\\n\\nForest, OK 79086\\n\\n2011-06-25 19:40:03 UTC 65412\\n\\n\\nFavorited 40\\n\\nFavorited 0\\n\\nComments 31\\n\\nViews 63\\n\\nVotes 12\\n\\nConsidered (43)\\n\\n\\nNo\\n\\nThe user #',\n",
       " 'source_documents': [Document(page_content='U.S. (Source: the npd Group). all knives feature high-carbon stainless steel blades which ensure the blades retain their ultra-sharp edge longer than conventional stainless steel. Each knife features an ergonomic metallic steel handle for greater durability. Set includes: 8-inch chef, 8-inch bread, 5-1/2-inch utility, 3-1/2-inch parer, 6 4.5-Inch steaks knives, all-purpose shears, sharpening shear and storage block with angled Heel. Not dishwasher safe. Hand wash with warm water and a mild detergent; rinse and dry immediately.\"], \"price\": \"None\", \"images\": {\"hi_res\": [\"https://m.media-amazon.com/images/I/81+3G1q1cgL._AC_SL1500_.jpg\",'),\n",
       "  Document(page_content='\"Kitchen Utensils & Gadgets\", \"Kitchen Knives & Accessories\", \"Knife Block Sets\"], \"details\": \"{\\\\\"Color\\\\\": \\\\\"Red\\\\\", \\\\\"Brand\\\\\": \\\\\"Farberware\\\\\", \\\\\"Blade Material\\\\\": \\\\\"Steel\\\\\", \\\\\"Blade Edge\\\\\": \\\\\"Serrated\\\\\", \\\\\"Item Dimensions LxWxH\\\\\": \\\\\"6.73 x 4.92 x 14.37 inches\\\\\", \\\\\"Style\\\\\": \\\\\"Ergonomic\\\\\", \\\\\"Number of Pieces\\\\\": \\\\\"13\\\\\", \\\\\"Is Dishwasher Safe\\\\\": \\\\\"No\\\\\", \\\\\"Handle Material\\\\\": \\\\\"Stainless Steel\\\\\", \\\\\"Construction Type\\\\\": \\\\\"Stamped\\\\\", \\\\\"Product Dimensions\\\\\": \\\\\"6.73 x 4.92 x 14.37 inches\\\\\", \\\\\"Item Weight\\\\\": \\\\\"6.24 pounds\\\\\", \\\\\"Manufacturer\\\\\": \\\\\"Farberware\\\\\", \\\\\"Item model number\\\\\": \\\\\"5191610\\\\\", \\\\\"Is Discontinued By Manufacturer\\\\\": \\\\\"No\\\\\", \\\\\"Date First Available\\\\\": \\\\\"November 8, 2017\\\\\"}\", \"parent_asin\":'),\n",
       "  Document(page_content='\"Kitchen Utensils & Gadgets\", \"Kitchen Knives & Accessories\", \"Asian Knives\", \"Sashimi Knives\"], \"details\": \"{\\\\\"Manufacturer\\\\\": \\\\\"Sekizo\\\\\", \\\\\"Item model number\\\\\": \\\\\"8115-A2L\\\\\", \\\\\"Is Discontinued By Manufacturer\\\\\": \\\\\"No\\\\\", \\\\\"Date First Available\\\\\": \\\\\"May 18, 2016\\\\\", \\\\\"Brand\\\\\": \\\\\"M.V. Trading\\\\\", \\\\\"Color\\\\\": \\\\\"Stainless Steel\\\\\", \\\\\"Handle Material\\\\\": \\\\\"Plastic,Steel\\\\\", \\\\\"Blade Edge\\\\\": \\\\\"Plain\\\\\", \\\\\"Blade Color\\\\\": \\\\\"Silver\\\\\"}\", \"parent_asin\": \"B01FV86UUY\", \"bought_together\": null, \"subtitle\": null, \"author\": null}'),\n",
       "  Document(page_content='\"/shop/wolfzoidgaming\", \"\", \"\", \"\", \"\", \"/shop/wolfzoidgaming\", \"\"]}, \"store\": \"VanlonPro\", \"categories\": [\"Home & Kitchen\", \"Kitchen & Dining\", \"Kitchen Utensils & Gadgets\", \"Kitchen Knives & Accessories\", \"Magnetic Knife Strips\"], \"details\": \"{\\\\\"Color\\\\\": \\\\\"Acrylic Shield\\\\\", \\\\\"Material\\\\\": \\\\\"Acrylic\\\\\", \\\\\"Brand\\\\\": \\\\\"VanlonPro\\\\\", \\\\\"Item Dimensions LxWxH\\\\\": \\\\\"8.66 x 1.57 x 9.45 inches\\\\\", \\\\\"Is Dishwasher Safe\\\\\": \\\\\"No\\\\\", \\\\\"Style\\\\\": \\\\\"Modern\\\\\", \\\\\"Product Dimensions\\\\\": \\\\\"8.66 x 1.57 x 9.45 inches\\\\\", \\\\\"Item Weight\\\\\": \\\\\"3.58 pounds\\\\\", \\\\\"Item model number\\\\\": \\\\\"Vanlon1199\\\\\", \\\\\"Best Sellers Rank\\\\\": {\\\\\"Kitchen & Dining\\\\\": 395687, \\\\\"Magnetic Knife Strips\\\\\": 253}, \\\\\"Date First Available\\\\\": \\\\\"October 17,')]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_question = \"Can you tell me what crossbows are available?\"\n",
    "llm = gpt2_model()\n",
    "answer = chat_answer(prompt_question, llm)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mTest prompt for NLP Amazon sales chatbot.\n",
      "        {\"main_category\": \"All Beauty\", \"title\": \"Magic Self-Adhesive Eyeliner, Waterproof Black Liquid Sticky Eyeliner for Eyelashes Extension, Long Lasting and No Glue Needed for Women Makeup\", \"average_rating\": 3.9, \"rating_number\": 47, \"features\": [\"[Easy to Use] Just like the magnetic eyeliner, it can absorb the eyelashes as long as it is drawn on the root of the eyelashes. But our liquid eyeliner does not contain magnets, nor does it require magnetic false eyelashes.\", \"[Save Makeup Time] Let the time to draw eyeliner replace the time to apply glue. Avoid spending a lot of time applying glue when wearing eyelashes, and also free you from glue allergies.\", \"[2-in-1 Function] All you need is a\n",
      "\n",
      "it for a whole day, it can be easily removed with makeup remover.\"], \"description\": [\"HOW TO USE\", \"Step 1:Draw eyeliner as\\u00a0normal eye liner makeup\\u00a0until\\u00a0it dry.\", \"Step 2:\", \"Adjust the size of eyelashes\\u00a0to fit your eye length, and put it on the eyeliner.\", \"Step 3:\", \"Press the eyelashes firmly against the roots of the natural eyelashes.\\u00a0No glue needed, easy to operate, and show your beautiful eyes.\"], \"price\": \"None\", \"images\": {\"hi_res\": [\"https://m.media-amazon.com/images/I/61v018KjGQL._SL1500_.jpg\", \"https://m.media-amazon.com/images/I/71BvdwLQjPL._SL1500_.jpg\", \"https://m.media-amazon.com/images/I/617UPYpzOzL._SL1500_.jpg\"], \"large\":\n",
      "\n",
      "wearing eyelashes, and also free you from glue allergies.\", \"[2-in-1 Function] All you need is a self-adhesive liquid eyeliner to have both eyeliner and eyelash sticking functions. It is a good tool for makeup, not only saving time but also saving money.\", \"[Reliable and Waterproof] The magic self-adhesive eyeliner is highly adhesive and waterproof. You don't need to worry about the eyelashes falling off and the makeup will spend. Make your eyes more charming, shiny and attractive.\", \"[Easy to Use and Remove] The eyeliner is compact and portable and the tip is soft and easy to operate. After wearing it for a whole day, it can be easily removed with makeup remover.\"], \"description\": [\"HOW TO\n",
      "\n",
      "{\"main_category\": \"All Beauty\", \"title\": \"Double-end Eyebrow pencil & Eyeliner pen,2 in 1 Microblading Eyebrow Pencil Makeup Long Lasting Waterproof & Smudgeproof Natural Looking Brows (Dark Brown)\", \"average_rating\": 4.4, \"rating_number\": 4, \"features\": [], \"description\": [], \"price\": \"None\", \"images\": {\"hi_res\": [\"https://m.media-amazon.com/images/I/61PNVVP-PsL._SL1250_.jpg\", \"https://m.media-amazon.com/images/I/61kaR7ScHjL._SL1238_.jpg\", \"https://m.media-amazon.com/images/I/611zRjK8BDL._SL1067_.jpg\", \"https://m.media-amazon.com/images/I/61fWPlNos1L._SL1000_.jpg\", \"https://m.media-amazon.com/images/I/81wImAf8ETL._SL1500_.jpg\", \"https://m.media-amazon.com/images/I/51w8te-MIsL._SL1000_.jpg\",\n",
      "        Question: What is the best eye liner?\n",
      "        Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the best eye liner?',\n",
       " 'chat_history': [],\n",
       " 'answer': '<pad>  \"Double-end  Eyebrow  pencil  &  Eyeliner  pen,2  in  1  Microblading  Eyebrow  Pencil  Makeup  Long  Lasting  Waterproof  &  Smudgeproof  Natural  Looking  Brows  (Dark  Brown)\"\\n',\n",
       " 'source_documents': [Document(page_content='{\"main_category\": \"All Beauty\", \"title\": \"Magic Self-Adhesive Eyeliner, Waterproof Black Liquid Sticky Eyeliner for Eyelashes Extension, Long Lasting and No Glue Needed for Women Makeup\", \"average_rating\": 3.9, \"rating_number\": 47, \"features\": [\"[Easy to Use] Just like the magnetic eyeliner, it can absorb the eyelashes as long as it is drawn on the root of the eyelashes. But our liquid eyeliner does not contain magnets, nor does it require magnetic false eyelashes.\", \"[Save Makeup Time] Let the time to draw eyeliner replace the time to apply glue. Avoid spending a lot of time applying glue when wearing eyelashes, and also free you from glue allergies.\", \"[2-in-1 Function] All you need is a'),\n",
       "  Document(page_content='it for a whole day, it can be easily removed with makeup remover.\"], \"description\": [\"HOW TO USE\", \"Step 1:Draw eyeliner as\\\\u00a0normal eye liner makeup\\\\u00a0until\\\\u00a0it dry.\", \"Step 2:\", \"Adjust the size of eyelashes\\\\u00a0to fit your eye length, and put it on the eyeliner.\", \"Step 3:\", \"Press the eyelashes firmly against the roots of the natural eyelashes.\\\\u00a0No glue needed, easy to operate, and show your beautiful eyes.\"], \"price\": \"None\", \"images\": {\"hi_res\": [\"https://m.media-amazon.com/images/I/61v018KjGQL._SL1500_.jpg\", \"https://m.media-amazon.com/images/I/71BvdwLQjPL._SL1500_.jpg\", \"https://m.media-amazon.com/images/I/617UPYpzOzL._SL1500_.jpg\"], \"large\":'),\n",
       "  Document(page_content='wearing eyelashes, and also free you from glue allergies.\", \"[2-in-1 Function] All you need is a self-adhesive liquid eyeliner to have both eyeliner and eyelash sticking functions. It is a good tool for makeup, not only saving time but also saving money.\", \"[Reliable and Waterproof] The magic self-adhesive eyeliner is highly adhesive and waterproof. You don\\'t need to worry about the eyelashes falling off and the makeup will spend. Make your eyes more charming, shiny and attractive.\", \"[Easy to Use and Remove] The eyeliner is compact and portable and the tip is soft and easy to operate. After wearing it for a whole day, it can be easily removed with makeup remover.\"], \"description\": [\"HOW TO'),\n",
       "  Document(page_content='{\"main_category\": \"All Beauty\", \"title\": \"Double-end Eyebrow pencil & Eyeliner pen,2 in 1 Microblading Eyebrow Pencil Makeup Long Lasting Waterproof & Smudgeproof Natural Looking Brows (Dark Brown)\", \"average_rating\": 4.4, \"rating_number\": 4, \"features\": [], \"description\": [], \"price\": \"None\", \"images\": {\"hi_res\": [\"https://m.media-amazon.com/images/I/61PNVVP-PsL._SL1250_.jpg\", \"https://m.media-amazon.com/images/I/61kaR7ScHjL._SL1238_.jpg\", \"https://m.media-amazon.com/images/I/611zRjK8BDL._SL1067_.jpg\", \"https://m.media-amazon.com/images/I/61fWPlNos1L._SL1000_.jpg\", \"https://m.media-amazon.com/images/I/81wImAf8ETL._SL1500_.jpg\", \"https://m.media-amazon.com/images/I/51w8te-MIsL._SL1000_.jpg\",')]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_question = \"What is the best eye liner?\"\n",
    "llm = t5_model()\n",
    "answer = chat_answer(prompt_question, llm)\n",
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
